import { DataNodeTokenPointDetail } from '@yozora/tokenizercore'
import { InlineDataNodeType } from '../base'


/**
 *
 */
export interface InlineTokenDelimiterItem<
  PotentialType extends string = 'opener' | 'closer' | 'both'
  > {
  /**
   * 潜在的类型
   */
  potentialType: PotentialType
  /**
   * 起始下标
   */
  startIndex: number
  /**
   * 结束下标
   */
  endIndex: number
  /**
   * 定界符厚度
   */
  thickness: number
}


/**
 *
 */
export interface InlinePotentialTokenItem<
  T extends InlineDataNodeType = InlineDataNodeType,
  > {
  /**
   *
   */
  type: T
  /**
   *
   */
  startIndex: number
  /**
   *
   */
  endIndex: number
  /**
   *
   */
  leftDelimiter?: InlineTokenDelimiterItem
  /**
   *
   */
  rightDelimiter?: InlineTokenDelimiterItem
  /**
   * Expose the internal list of raw content fragments that need further
   * processing, the list will be handed over to the context for recursive
   * analysis to get the internal tokens of the current inline token.
   *
   * These content fragments will be processed before assemblePreMatchState.
   */
  innerRawContents?: {
    /**
     *
     */
    startIndex: number
    /**
     *
     */
    endIndex: number
  }[]
}


/**
 * State of pre-match phase
 */
export interface InlineTokenizerPreMatchPhaseState<
  T extends InlineDataNodeType = InlineDataNodeType,
  > {
  /**
   *
   */
  type: T
  /**
   *
   */
  children?: InlineTokenizerPreMatchPhaseState[]
}


/**
 * State-tree of pre-match phase
 */
export interface InlineTokenizerPreMatchPhaseStateTree {
  /**
   *
   */
  type: 'root'
  /**
   *
   */
  children: InlineTokenizerPreMatchPhaseState[]
}


/**
 * Hooks in the pre-match phase
 */
export interface InlineTokenizerPreMatchPhaseHook<
  T extends InlineDataNodeType = InlineDataNodeType,
  PMS extends InlineTokenizerPreMatchPhaseState<T> = InlineTokenizerPreMatchPhaseState<T>,
  > {
  /**
   * This method will be called many times when processing codePositions
   * of one leaf block node. This is because the content seen by the current
   * tokenizer may be multiple content segments generated by splitting the
   * original content when the tokenizer with higher priority is processed.
   * These fragments will be passed to eatDelimiter for processing in turn.
   *
   * # Params
   *
   * - [startIndex, endIndex) is a half-closed interval that specifies the
   *   range of available positions for codePositions
   *
   * - delimiters is a pre-prepared container for collecting DelimiterItems
   *   found during multiple calls to this function when processing the content
   *   of a leaf block node
   *
   * - precedingCodePosition is the preceding character info of the
   *   codePositions[startIndex] (skipped internal atomic tokens).
   *   `null` means no such character
   *
   * - followingCodePosition is the following character info of the
   *   codePositions[endIndex-1] (skipped internal atomic tokens).
   *   `null` means no such character
   */
  eatDelimiters: (
    codePositions: DataNodeTokenPointDetail[],
    startIndex: number,
    endIndex: number,
    delimiters: InlineTokenDelimiterItem[],
    precedingCodePosition: DataNodeTokenPointDetail | null,
    followingCodePosition: DataNodeTokenPointDetail | null,
  ) => void

  /**
   * Process the delimiter stack.
   *
   * # Params
   *
   * - delimiters are DelimiterItems collected in the multiple eatDelimiters
   *   executed while processing a leaf block node
   */
  eatTokens: (
    codePositions: DataNodeTokenPointDetail[],
    delimiters: InlineTokenDelimiterItem[],
  ) => InlinePotentialTokenItem<T>[]

  /**
   * Assemble tokens and innerTokens to PreMatchState
   */
  assemblePreMatchState: (
    codePositions: DataNodeTokenPointDetail[],
    token: InlinePotentialTokenItem<T>,
    innerState: InlineTokenizerPreMatchPhaseState[],
  ) => PMS
}
