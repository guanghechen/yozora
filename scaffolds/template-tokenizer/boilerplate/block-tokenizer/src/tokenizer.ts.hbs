import type { EnhancedYastNodePoint, YastMeta } from '@yozora/tokenizercore'
import type {
  BlockTokenizer,
  BlockTokenizerMatchPhaseHook,
  BlockTokenizerMatchPhaseState,
  BlockTokenizerParsePhaseHook,
  BlockTokenizerPostMatchPhaseHook,
  BlockTokenizerPostMatchPhaseState,
  BlockTokenizerPostParsePhaseHook,
  BlockTokenizerProps,
  EatingLineInfo,
  PhrasingContentLine,
  ResultOfEatAndInterruptPreviousSibling,
  ResultOfEatContinuationText,
  ResultOfEatLazyContinuationText,
  ResultOfEatOpener,
  ResultOfParse,
  YastBlockNode,
} from '@yozora/tokenizercore-block'
import type {
  {{{pascalCase tokenizerName}}} as PS,
  {{{pascalCase tokenizerName}}}MatchPhaseState as MS,
  {{{pascalCase tokenizerName}}}PostMatchPhaseState as PMS,
  {{{pascalCase tokenizerName}}}Type as T,
} from './types'
import { BaseBlockTokenizer } from '@yozora/tokenizercore-block'
import { {{{pascalCase tokenizerName}}}Type } from './types'


/**
 * Params for constructing {{{pascalCase tokenizerName}}}Tokenizer
 */
export interface {{{pascalCase tokenizerName}}}TokenizerProps extends BlockTokenizerProps {

}


/**
 * Lexical Analyzer for {{{pascalCase tokenizerName}}}
 */
export class {{{pascalCase tokenizerName}}}Tokenizer extends BaseBlockTokenizer<T, MS, PMS> implements
  BlockTokenizer<T, MS, PMS>{{#if usingHooks}},{{/if}}
{{#if useBlockTokenizerMatchPhaseHook}}
  BlockTokenizerMatchPhaseHook<T, MS>{{#if BlockTokenizerMatchPhaseHook__isNotLastHook}},{{/if}}
{{/if}}
{{#if useBlockTokenizerPostMatchPhaseHook}}
  BlockTokenizerPostMatchPhaseHook{{#if BlockTokenizerPostMatchPhaseHook__isNotLastHook}},{{/if}}
{{/if}}
{{#if useBlockTokenizerParsePhaseHook}}
  BlockTokenizerParsePhaseHook<T, PMS, PS>{{#if BlockTokenizerParsePhaseHook__isNotLastHook}},{{/if}}
{{/if}}
{{#if useBlockTokenizerPostParsePhaseHook}}
  BlockTokenizerPostParsePhaseHook{{#if BlockTokenizerPostParsePhaseHook__isNotLastHook}},{{/if}}
{{/if}}
{
  public readonly name = '{{{pascalCase tokenizerName}}}Tokenizer'
  public readonly uniqueTypes: T[] = [{{{pascalCase tokenizerName}}}Type]

  public constructor(props: {{{pascalCase tokenizerName}}}TokenizerProps = {}) {
    super({
      ...props,
      interruptableTypes: props.interruptableTypes || [],
    })
  }
{{#if useBlockTokenizerMatchPhaseHook}}

  /**
   * @override
   * @see BlockTokenizerMatchPhaseHook
   */
  public eatOpener(
    nodePoints: ReadonlyArray<EnhancedYastNodePoint>,
    eatingInfo: EatingLineInfo,
    parentState: Readonly<BlockTokenizerMatchPhaseState>,
  ): ResultOfEatOpener<T, MS> {
    const { isBlankLine, startIndex, endIndex, firstNonWhitespaceIndex } = eatingInfo
    if (isBlankLine) return null

    const line: PhrasingContentLine = {
      startIndex,
      endIndex,
      firstNonWhitespaceIndex,
    }

    const state: MS = {
      type: {{{pascalCase tokenizerName}}}Type,
      lines: [line],
    }

    return { nextIndex: endIndex, state }
  }

  // /**
  //  * @override
  //  * @see BlockTokenizerMatchPhaseHook
  //  */
  // public eatAndInterruptPreviousSibling(
  //   nodePoints: ReadonlyArray<EnhancedYastNodePoint>,
  //   eatingInfo: EatingLineInfo,
  //   previousSiblingState: Readonly<BlockTokenizerMatchPhaseState>,
  //   parentState: Readonly<BlockTokenizerMatchPhaseState>,
  // ): ResultOfEatAndInterruptPreviousSibling<T, MS> {
  //   return null
  // }

  // /**
  //  * @override
  //  * @see BlockTokenizerMatchPhaseHook
  //  */
  // public eatContinuationText(
  //   nodePoints: ReadonlyArray<EnhancedYastNodePoint>,
  //   eatingInfo: EatingLineInfo,
  //   state: MS,
  //   parentState: Readonly<BlockTokenizerMatchPhaseState>,
  // ): ResultOfEatContinuationText {
  //   return { failed: true }
  // }

  // /**
  //  * @override
  //  * @see BlockTokenizerMatchPhaseHook
  //  */
  // public eatLazyContinuationText(
  //   nodePoints: ReadonlyArray<EnhancedYastNodePoint>,
  //   eatingInfo: EatingLineInfo,
  //   state: MS,
  //   parentState: Readonly<BlockTokenizerMatchPhaseState>,
  // ): ResultOfEatLazyContinuationText {
  //   const result = this.eatContinuationText(nodePoints, eatingInfo, state, parentState)
  //   const { nextIndex, saturated } = result
  //   return { nextIndex, saturated } as ResultOfEatLazyContinuationText
  // }
{{/if}}
{{#if useBlockTokenizerPostMatchPhaseHook}}

  /**
   * @override
   * @see BlockTokenizerPostMatchPhaseHook
   */
  public transformMatch(
    nodePoints: ReadonlyArray<EnhancedYastNodePoint>,
    states: ReadonlyArray<BlockTokenizerPostMatchPhaseState>,
  ): BlockTokenizerPostMatchPhaseState[] {
    return states as BlockTokenizerPostMatchPhaseState[]
  }
{{/if}}
{{#if useBlockTokenizerParsePhaseHook}}

  /**
   * @override
   * @see BlockTokenizerParsePhaseHook
   */
  public parse(
    nodePoints: ReadonlyArray<EnhancedYastNodePoint>,
    postMatchState: Readonly<PMS>,
    children?: YastBlockNode[],
  ): ResultOfParse<T, PS> {
    const state: PS = {
      type: postMatchState.type,
    }
    return { classification: 'flow', state }
  }
{{/if}}
{{#if useBlockTokenizerPostParsePhaseHook}}

  /**
   * @override
   * @see BlockTokenizerPostParsePhaseHook
   */
  public transformParse(
    nodePoints: ReadonlyArray<EnhancedYastNodePoint>,
    states: ReadonlyArray<YastBlockNode>,
    meta: Readonly<YastMeta>,
  ): YastBlockNode[] {
    return states as YastBlockNode[]
  }
{{/if}}
}
