{{#if useBlockTokenizerPreMatchPhaseHook}}
import { ParagraphDataNodeType } from '@yozora/tokenizer-paragraph'
{{/if}}
import {
  BaseBlockTokenizer,
  BlockTokenizer,
{{#if useBlockTokenizerPreMatchPhaseHook}}
  BlockTokenizerEatingInfo,
{{/if}}
{{#if useBlockTokenizerMatchPhaseHook}}
  BlockTokenizerMatchPhaseHook,
{{/if}}
  BlockTokenizerMatchPhaseState,
{{#if useBlockTokenizerParsePhaseHook}}
  BlockTokenizerParsePhaseHook,
{{/if}}
{{#if useBlockTokenizerPreMatchPhaseHook}}
  BlockTokenizerPreMatchPhaseHook,
{{/if}}
  BlockTokenizerPreMatchPhaseState,
  BlockTokenizerPreParsePhaseState,
{{#if useBlockTokenizerPostMatchPhaseHook}}
  BlockTokenizerPostMatchPhaseHook,
{{/if}}
} from '@yozora/block-tokenizer-core'
import { DataNodeTokenPointDetail } from '@yozora/tokenizercore'
import { {{{pascalCase tokenizerName}}}DataNode, {{{pascalCase tokenizerName}}}DataNodeType } from './types'


type T = {{{pascalCase tokenizerName}}}DataNodeType


/**
 * State of pre-match phase of {{{pascalCase tokenizerName}}}Tokenizer
 */
export interface {{{pascalCase tokenizerName}}}TokenizerPreMatchPhaseState
  extends BlockTokenizerPreMatchPhaseState<T> {
  /**
   *
   */
  content: DataNodeTokenPointDetail[]
}


/**
 * State of match phase of {{{pascalCase tokenizerName}}}Tokenizer
 */
export interface {{{pascalCase tokenizerName}}}TokenizerMatchPhaseState
  extends BlockTokenizerMatchPhaseState<T> {
  /**
   *
   */
  content: DataNodeTokenPointDetail[]
}


/**
 * Lexical Analyzer for {{{pascalCase tokenizerName}}}DataNode
 */
export class {{{pascalCase tokenizerName}}}Tokenizer extends BaseBlockTokenizer<T>
  implements
    BlockTokenizer<T>,
{{#if useBlockTokenizerPreMatchPhaseHook}}
    BlockTokenizerPreMatchPhaseHook<T, {{{pascalCase tokenizerName}}}TokenizerPreMatchPhaseState>,
{{/if}}
{{#if useBlockTokenizerMatchPhaseHook}}
    BlockTokenizerMatchPhaseHook<T, {{{pascalCase tokenizerName}}}TokenizerPreMatchPhaseState, {{{pascalCase tokenizerName}}}TokenizerMatchPhaseState>,
{{/if}}
{{#if useBlockTokenizerPostMatchPhaseHook}}
    BlockTokenizerPostMatchPhaseHook<T, BlockTokenizerMatchPhaseState, {{{pascalCase tokenizerName}}}TokenizerMatchPhaseState>,
{{/if}}
{{#if useBlockTokenizerParsePhaseHook}}
    BlockTokenizerParsePhaseHook<T, {{{pascalCase tokenizerName}}}TokenizerMatchPhaseState, {{{pascalCase tokenizerName}}}DataNode>
{{/if}}
{
  public readonly name = '{{{pascalCase tokenizerName}}}Tokenizer'
  public readonly uniqueTypes: T[] = [{{{pascalCase tokenizerName}}}DataNodeType]

{{#if useBlockTokenizerPreMatchPhaseHook}}
  /**
   * hook of @BlockTokenizerPreMatchPhaseHook
   */
  public eatNewMarker(
    codePositions: DataNodeTokenPointDetail[],
    eatingInfo: BlockTokenizerEatingInfo,
    parentState: Readonly<BlockTokenizerPreMatchPhaseState>
  ): {
    nextIndex: number,
    state: {{{pascalCase tokenizerName}}}TokenizerPreMatchPhaseState,
    nextState?: BlockTokenizerPreMatchPhaseState,
  } | null {
    const { isBlankLine, firstNonWhiteSpaceIndex, endIndex } = eatingInfo
    if (isBlankLine) return null

    const state: {{{pascalCase tokenizerName}}}TokenizerPreMatchPhaseState = {
      type: {{{pascalCase tokenizerName}}}DataNodeType,
      opening: true,
      parent: parentState,
      content: codePositions.slice(firstNonWhiteSpaceIndex, endIndex),
    }
    return { nextIndex: endIndex, state }
  }

  // /**
  //  * hook of @BlockTokenizerPreMatchPhaseHook
  //  */
  // public eatAndInterruptPreviousSibling(
  //   codePositions: DataNodeTokenPointDetail[],
  //   eatingInfo: BlockTokenizerEatingInfo,
  //   parentState: Readonly<BlockTokenizerPreMatchPhaseState>,
  //   previousSiblingState: Readonly<BlockTokenizerPreMatchPhaseState>,
  // ): {
  //   nextIndex: number,
  //   state: {{{pascalCase tokenizerName}}}TokenizerPreMatchPhaseState,
  //   shouldRemovePreviousSibling: boolean,
  //   nextState?: BlockTokenizerPreMatchPhaseState,
  // } | null {
  //   const self = this
  //   switch (previousSiblingState.type) {
  //     case ParagraphDataNodeType: {
  //       if (previousSiblingState.type !== ParagraphDataNodeType) return null
  //       const eatingResult = self.eatNewMarker(codePositions, eatingInfo, parentState)
  //       if (eatingResult == null) return null
  //       return { ...eatingResult, shouldRemovePreviousSibling: false }
  //     }
  //     default:
  //       return null
  //   }
  // }

  // /**
  //  * hook of @BlockTokenizerPreMatchPhaseHook
  //  */
  // public eatContinuationText(
  //   codePositions: DataNodeTokenPointDetail[],
  //   eatingInfo: BlockTokenizerEatingInfo,
  //   state: {{{pascalCase tokenizerName}}}TokenizerPreMatchPhaseState,
  // ): number | -1 {
  //   return -1
  // }

  // /**
  //  * hook of @BlockTokenizerPreMatchPhaseHook
  //  */
  // public eatLazyContinuationText(
  //   codePositions: DataNodeTokenPointDetail[],
  //   eatingInfo: BlockTokenizerEatingInfo,
  //   state: {{{pascalCase tokenizerName}}}TokenizerPreMatchPhaseState,
  // ): number | -1 {
  //   return -1
  // }

  // /**
  //  * hook of @BlockTokenizerPreMatchPhaseHook
  //  */
  // public shouldAcceptChild(
  //   state: {{{pascalCase tokenizerName}}}TokenizerPreMatchPhaseState,
  //   childState: BlockTokenizerPreMatchPhaseState,
  // ): boolean {
  //   return true
  // }

  // /**
  //  * hook of @BlockTokenizerPreMatchPhaseHook
  //  */
  // public beforeAcceptChild(
  //   state: {{{pascalCase tokenizerName}}}TokenizerPreMatchPhaseState,
  //   childState: BlockTokenizerPreMatchPhaseState,
  // ): void {
  //
  // }
{{/if}}
{{#if useBlockTokenizerMatchPhaseHook}}

  /**
   * hook of @BlockTokenizerMatchPhaseHook
   */
  public match(
    preMatchPhaseState: {{{pascalCase tokenizerName}}}TokenizerPreMatchPhaseState,
  ): {{{pascalCase tokenizerName}}}TokenizerMatchPhaseState {
    const result: {{{pascalCase tokenizerName}}}TokenizerMatchPhaseState = {
      type: preMatchPhaseState.type,
      classify: 'flow',
      content: preMatchPhaseState.content,
    }
    return result
  }
{{/if}}
{{#if useBlockTokenizerPostMatchPhaseHook}}

  /**
   * hook of @BlockTokenizerPostMatchPhaseHook
   */
  public transformMatch(
    originalMatchPhaseState: Readonly<BlockTokenizerMatchPhaseState>,
    originalPreviousSiblingState?: Readonly<BlockTokenizerMatchPhaseState>,
  ): {{{pascalCase tokenizerName}}}TokenizerMatchPhaseState | null | false {
    return null
  }
{{/if}}
{{#if useBlockTokenizerParsePhaseHook}}

  /**
   * hook of @BlockTokenizerParseFlowPhaseHook
   */
  public parseFlow(
    matchPhaseState: {{{pascalCase tokenizerName}}}TokenizerMatchPhaseState,
    preParsePhaseState: BlockTokenizerPreParsePhaseState,
  ): {{{pascalCase tokenizerName}}}DataNode {
    const self = this
    const result: {{{pascalCase tokenizerName}}}DataNode = {
      type: matchPhaseState.type,
      data: {
        children: [],
      }
    }
    if (self.parseInlineData != null) {
      const innerData = self.parseInlineData(
        matchPhaseState.content, 0, matchPhaseState.content.length, preParsePhaseState.meta)
      result.data!.children = innerData
    }
    return result
  }
{{/if}}
}
