import {
  BaseBlockDataNodeTokenizer,
  BlockDataNode,
  BlockDataNodeEatingLineInfo,
  BlockDataNodeEatingResult,
  BlockDataNodeMatchResult,
  BlockDataNodeMatchState,
  BlockDataNodeTokenizer,
  DataNodeTokenPointDetail,
  InlineDataNodeParseFunc,
} from '@yozora/tokenizer-core'
import {
  {{{pascalCase tokenizerName}}}DataNode,
  {{{pascalCase tokenizerName}}}DataNodeData,
  {{{pascalCase tokenizerName}}}DataNodeType,
} from './types'


type T = {{{pascalCase tokenizerName}}}DataNodeType


export interface {{{pascalCase tokenizerName}}}DataNodeMatchState extends BlockDataNodeMatchState<T> {

}


export interface {{{pascalCase tokenizerName}}}DataNodeMatchResult extends BlockDataNodeMatchResult<T> {

}


/**
 * Lexical Analyzer for {{{pascalCase tokenizerName}}}DataNode
 */
export class {{{pascalCase tokenizerName}}}Tokenizer extends BaseBlockDataNodeTokenizer<
  T,
  {{{pascalCase tokenizerName}}}DataNodeData,
  {{{pascalCase tokenizerName}}}DataNodeMatchState,
  {{{pascalCase tokenizerName}}}DataNodeMatchResult>
  implements BlockDataNodeTokenizer<
  T,
  {{{pascalCase tokenizerName}}}DataNodeData,
  {{{pascalCase tokenizerName}}}DataNodeMatchState,
  {{{pascalCase tokenizerName}}}DataNodeMatchResult> {
  public readonly name = '{{{pascalCase tokenizerName}}}Tokenizer'
  public readonly recognizedTypes: T[] = [{{{pascalCase tokenizerName}}}DataNodeType]

  /**
   * override
   */
  public eatNewMarker(
    codePoints: DataNodeTokenPointDetail[],
    eatingLineInfo: BlockDataNodeEatingLineInfo,
    parentState: BlockDataNodeMatchState,
  ): BlockDataNodeEatingResult<T, {{{pascalCase tokenizerName}}}DataNodeMatchState> | null {
    return null
  }

  /**
   * override
   */
  public eatContinuationText(
    codePoints: DataNodeTokenPointDetail[],
    eatingLineInfo: BlockDataNodeEatingLineInfo,
    state: {{{pascalCase tokenizerName}}}DataNodeMatchState,
  ): BlockDataNodeEatingResult<T, {{{pascalCase tokenizerName}}}DataNodeMatchState> | null {
    return null
  }

  // /**
  //  * override
  //  */
  // public eatLazyContinuationText(
  //   codePoints: DataNodeTokenPointDetail[],
  //   eatingLineInfo: BlockDataNodeEatingLineInfo,
  //   state: {{{pascalCase tokenizerName}}}DataNodeMatchState,
  // ): BlockDataNodeEatingResult<T, {{{pascalCase tokenizerName}}}DataNodeMatchState> | null {
  //  return null
  // }

  /**
   * override
   */
  public match(state: {{{pascalCase tokenizerName}}}DataNodeMatchState): {{{pascalCase tokenizerName}}}DataNodeMatchResult {
    const result: {{{pascalCase tokenizerName}}}DataNodeMatchResult = {

    } as any
    return result
  }

  /**
   * override
   */
  public parse(
    codePoints: DataNodeTokenPointDetail[],
    matchResult: {{{pascalCase tokenizerName}}}DataNodeMatchResult,
    children?: BlockDataNode[],
    parseInline?: InlineDataNodeParseFunc,
  ): {{{pascalCase tokenizerName}}}DataNode {
    const result: {{{pascalCase tokenizerName}}}DataNode = {

    } as any
    return result
  }

  // /**
  //  * override
  //  */
  // public shouldAcceptChild(
  //   state: {{{pascalCase tokenizerName}}}ListDataNodeMatchState,
  //   childState: BlockDataNodeMatchState,
  // ): boolean {
  //   return false
  // }

  // /**
  //  * override
  //  */
  // public beforeAcceptChild(state: {{{pascalCase tokenizerName}}}DataNodeMatchState): void {
  //
  // }

  // /**
  //  * override
  //  */
  // public beforeCloseMatchState(state: {{{pascalCase tokenizerName}}}DataNodeMatchState): void {
  //
  // }
}
