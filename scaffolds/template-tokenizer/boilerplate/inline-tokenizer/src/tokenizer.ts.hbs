import { AsciiCodePoint } from '@yozora/character'
import { DataNodeTokenPointDetail } from '@yozora/tokenizercore'
import {
  BaseInlineTokenizer,
  InlineTokenizer,
  InlineTokenizerMatchPhaseHook,
  InlineTokenizerParsePhaseHook,
  InlineTokenizerParsePhaseState,
  InlineTokenizerPreMatchPhaseHook,
  InlineTokenizerPreMatchPhaseState,
  RawContent,
} from '@yozora/tokenizercore-inline'
import {
  {{{pascalCase tokenizerName}}}DataNode,
  {{{pascalCase tokenizerName}}}DataNodeType,
  {{{pascalCase tokenizerName}}}MatchPhaseState,
  {{{pascalCase tokenizerName}}}PotentialToken,
  {{{pascalCase tokenizerName}}}PreMatchPhaseState,
  {{{pascalCase tokenizerName}}}TokenDelimiter,
} from './types'


type T = {{{pascalCase tokenizerName}}}DataNodeType


/**
 * Lexical Analyzer for {{{pascalCase tokenizerName}}}DataNode
 */
export class {{{pascalCase tokenizerName}}}Tokenizer extends BaseInlineTokenizer<T>
  implements
    InlineTokenizer<T>,
    InlineTokenizerPreMatchPhaseHook<
      T,
      {{{pascalCase tokenizerName}}}PreMatchPhaseState,
      {{{pascalCase tokenizerName}}}TokenDelimiter,
      {{{pascalCase tokenizerName}}}PotentialToken>,
    InlineTokenizerMatchPhaseHook<
      T,
      {{{pascalCase tokenizerName}}}PreMatchPhaseState,
      {{{pascalCase tokenizerName}}}MatchPhaseState>,
    InlineTokenizerParsePhaseHook<
      T,
      {{{pascalCase tokenizerName}}}MatchPhaseState,
      {{{pascalCase tokenizerName}}}DataNode>
{
  public readonly name = '{{{pascalCase tokenizerName}}}Tokenizer'
  public readonly uniqueTypes: T[] = [{{{pascalCase tokenizerName}}}DataNodeType]

  /**
   * hook of @InlineTokenizerPreMatchPhaseHook
   */
  public eatDelimiters(
    rawContent: RawContent,
    startIndex: number,
    endIndex: number,
    delimiters: {{{pascalCase tokenizerName}}}TokenDelimiter[],
    precedingCodePosition: DataNodeTokenPointDetail | null,
    followingCodePosition: DataNodeTokenPointDetail | null,
  ): void {
    const { codePositions } = rawContent
    for (let i = startIndex; i < endIndex; ++i) {
      const p = codePositions[i]
      switch (p.codePoint) {
        case AsciiCodePoint.BACK_SLASH:
          i += 1
          break
        case AsciiCodePoint.NULL: {
          // TODO doing some thing
          break
        }
      }
    }
  }

  /**
   * hook of @InlineTokenizerPreMatchPhaseHook
   */
  public eatPotentialTokens(
    rawContent: RawContent,
    delimiters: {{{pascalCase tokenizerName}}}TokenDelimiter[],
  ): {{{pascalCase tokenizerName}}}PotentialToken[] {
    const potentialTokens: {{{pascalCase tokenizerName}}}PotentialToken[] = []

    let opener: {{{pascalCase tokenizerName}}}TokenDelimiter | null = null
    for (const delimiter of delimiters) {
      switch (delimiter.type) {
        case 'opener':
          opener = delimiter
          break
        case 'both':
          if (opener == null) {
            opener = delimiter
            break
          }
        case 'closer': {
          if (opener == null) break
          const closer = delimiter
          const potentialToken: {{{pascalCase tokenizerName}}}PotentialToken = {
            type: {{{pascalCase tokenizerName}}}DataNodeType,
            startIndex: opener.startIndex,
            endIndex: closer.endIndex,
            openerDelimiter: opener,
            closerDelimiter: closer,
            innerRawContents: [{
              startIndex: opener.endIndex,
              endIndex: closer.startIndex,
            }]
          }
          potentialTokens.push(potentialToken)
          break
        }
      }
    }
    return potentialTokens
  }

  /**
   * hook of @InlineTokenizerPreMatchPhaseHook
   */
  public assemblePreMatchState(
    rawContent: RawContent,
    potentialToken: {{{pascalCase tokenizerName}}}PotentialToken,
    innerState: InlineTokenizerPreMatchPhaseState[],
  ): {{{pascalCase tokenizerName}}}PreMatchPhaseState {
    const result: {{{pascalCase tokenizerName}}}PreMatchPhaseState = {
      type: {{{pascalCase tokenizerName}}}DataNodeType,
      startIndex: potentialToken.startIndex,
      endIndex: potentialToken.endIndex,
      openerDelimiter: potentialToken.openerDelimiter,
      closerDelimiter: potentialToken.closerDelimiter,
      children: innerState,
    }
    return result
  }

  /**
   * hook of @InlineTokenizerMatchPhaseHook
   */
  public match(
    rawContent: RawContent,
    preMatchPhaseState: {{{pascalCase tokenizerName}}}PreMatchPhaseState,
  ): {{{pascalCase tokenizerName}}}MatchPhaseState | false {
    const result: {{{pascalCase tokenizerName}}}MatchPhaseState = {
      type: {{{pascalCase tokenizerName}}}DataNodeType,
      startIndex: preMatchPhaseState.startIndex,
      endIndex: preMatchPhaseState.endIndex,
      openerDelimiter: preMatchPhaseState.openerDelimiter,
      closerDelimiter: preMatchPhaseState.closerDelimiter,
    }
    return result
  }

  /**
   * hook of @InlineTokenizerParsePhaseHook
   */
  public parse(
    rawContent: RawContent,
    matchPhaseState: {{{pascalCase tokenizerName}}}MatchPhaseState,
    parsedChildren?: InlineTokenizerParsePhaseState[],
  ): {{{pascalCase tokenizerName}}}DataNode {
    const result: {{{pascalCase tokenizerName}}}DataNode = {
      type: {{{pascalCase tokenizerName}}}DataNodeType,
      children: parsedChildren || [],
    }
    return result
  }
}
