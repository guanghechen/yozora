import type {
  EnhancedYastNodePoint,
  YastMeta as M,
} from '@yozora/tokenizercore'
import type {
  InlinePotentialToken,
  InlineTokenizer,
  InlineTokenizerMatchPhaseHook,
  InlineTokenizerParsePhaseHook,
  ResultOfEatDelimiters,
  ResultOfEatPotentialTokens,
  YastInlineNode,
} from '@yozora/tokenizercore-inline'
import type {
  {{{pascalCase tokenizerName}}} as PS,
  {{{pascalCase tokenizerName}}}MatchPhaseState as MS,
  {{{pascalCase tokenizerName}}}TokenDelimiter as TD,
  {{{pascalCase tokenizerName}}}Type as T,
} from './types'
import { AsciiCodePoint } from '@yozora/character'
import { BaseInlineTokenizer } from '@yozora/tokenizercore-inline'
import { {{{pascalCase tokenizerName}}}Type } from './types'


type PT = InlinePotentialToken<T>


/**
 * Lexical Analyzer for {{{pascalCase tokenizerName}}}
 */
export class {{{pascalCase tokenizerName}}}Tokenizer extends BaseInlineTokenizer<T> implements
  InlineTokenizer<T>,
  InlineTokenizerMatchPhaseHook<T, M, MS, TD>,
  InlineTokenizerParsePhaseHook<T, M, MS, PS>
{
  public readonly name = '{{{pascalCase tokenizerName}}}Tokenizer'
  public readonly uniqueTypes: T[] = [{{{pascalCase tokenizerName}}}Type]

  /**
   * @override
   * @see InlineTokenizerMatchPhaseHook
   */
  public * eatDelimiters(
    nodePoints: ReadonlyArray<EnhancedYastNodePoint>,
  ): ResultOfEatDelimiters<TD> {
    const delimiters: TD[] = []
    while (true) {
      const nextParams = yield
      if (nextParams == null) break

      const { startIndex, endIndex } = nextParams
      for (let i = startIndex; i < endIndex; ++i) {
        const p = nodePoints[i]
        switch (p.codePoint) {
          case AsciiCodePoint.BACK_SLASH:
            i += 1
            break
          case AsciiCodePoint.NULL: {
            // TODO doing some thing
            break
          }
        }
      }
    }
    return delimiters
  }

  /**
   * @override
   * @see InlineTokenizerMatchPhaseHoo
   */
  public eatPotentialTokens(
    nodePoints: ReadonlyArray<EnhancedYastNodePoint>,
    meta: Readonly<M>,
    delimiters: TD[]
  ): ResultOfEatPotentialTokens<T> {
    const results: PT[] = []

    let opener: TD | null = null
    for (const delimiter of delimiters) {
      switch (delimiter.type) {
        case 'opener':
          opener = delimiter
          break
        case 'both':
          if (opener == null) {
            opener = delimiter
            break
          }
        case 'closer': {
          if (opener == null) break
          const closer = delimiter
          const state: MS = {
            type: {{{pascalCase tokenizerName}}}Type,
            openerDelimiter: opener,
            closerDelimiter: closer,
          }
          results.push({
            state,
            startIndex: opener.startIndex,
            endIndex: closer.endIndex,
            innerRawContents: [{
              startIndex: opener.endIndex,
              endIndex: closer.startIndex,
            }]
          })
          opener = null
          break
        }
      }
    }
    return results
  }

  /**
   * @override
   * @see InlineTokenizerParsePhaseHook
   */
  public parse(
    nodePoints: ReadonlyArray<EnhancedYastNodePoint>,
    meta: Readonly<M>,
    matchPhaseState: MS,
    parsedChildren?: YastInlineNode[],
  ): PS {
    const result: PS = {
      type: {{{pascalCase tokenizerName}}}Type,
      children: parsedChildren || [],
    }
    return result
  }
}
