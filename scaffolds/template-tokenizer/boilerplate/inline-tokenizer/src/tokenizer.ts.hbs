import type {
  InlineTokenizer,
  InlineTokenizerMatchPhaseHook,
  InlineTokenizerParsePhaseHook,
  InlineTokenizerParsePhaseState,
  InlineTokenizerPreMatchPhaseHook,
  InlineTokenizerPreMatchPhaseState,
  NextParamsOfEatDelimiters,
  RawContent,
} from '@yozora/tokenizercore-inline'
import type {
  {{{pascalCase tokenizerName}}}DataNode,
  {{{pascalCase tokenizerName}}}MatchPhaseState,
  {{{pascalCase tokenizerName}}}PotentialToken,
  {{{pascalCase tokenizerName}}}PreMatchPhaseState,
  {{{pascalCase tokenizerName}}}TokenDelimiter,
  {{{pascalCase tokenizerName}}}Type as T,
} from './types'
import { AsciiCodePoint } from '@yozora/character'
import { BaseInlineTokenizer } from '@yozora/tokenizercore-inline'
import { {{{pascalCase tokenizerName}}}Type } from './types'


/**
 * Lexical Analyzer for {{{pascalCase tokenizerName}}}
 */
export class {{{pascalCase tokenizerName}}}Tokenizer extends BaseInlineTokenizer<T>
  implements
    InlineTokenizer<T>,
    InlineTokenizerPreMatchPhaseHook<
      T,
      {{{pascalCase tokenizerName}}}PreMatchPhaseState,
      {{{pascalCase tokenizerName}}}TokenDelimiter,
      {{{pascalCase tokenizerName}}}PotentialToken>,
    InlineTokenizerMatchPhaseHook<
      T,
      {{{pascalCase tokenizerName}}}PreMatchPhaseState,
      {{{pascalCase tokenizerName}}}MatchPhaseState>,
    InlineTokenizerParsePhaseHook<
      T,
      {{{pascalCase tokenizerName}}}MatchPhaseState,
      {{{pascalCase tokenizerName}}}>
{
  public readonly name = '{{{pascalCase tokenizerName}}}Tokenizer'
  public readonly uniqueTypes: T[] = [{{{pascalCase tokenizerName}}}Type]

  /**
   * hook of @InlineTokenizerPreMatchPhaseHook
   */
  public * eatDelimiters(
    rawContent: RawContent,
    blockStartIndex: number,
    blockEndIndex: number,
  ): Iterator<void, {{{pascalCase tokenizerName}}}TokenDelimiter[], NextParamsOfEatDelimiters | null> {
    const { nodePoints } = rawContent
    const delimiters: {{{pascalCase tokenizerName}}}TokenDelimiter[] = []

    while (true) {
      const nextParams = yield
      if (nextParams == null) break

      const { startIndex, endIndex } = nextParams
      for (let i = startIndex; i < endIndex; ++i) {
        const p = nodePoints[i]
        switch (p.codePoint) {
          case AsciiCodePoint.BACK_SLASH:
            i += 1
            break
          case AsciiCodePoint.NULL: {
            // TODO doing some thing
            break
          }
        }
      }
    }
    return delimiters
  }

  /**
   * hook of @InlineTokenizerPreMatchPhaseHook
   */
  public eatPotentialTokens(
    rawContent: RawContent,
    delimiters: {{{pascalCase tokenizerName}}}TokenDelimiter[],
  ): {{{pascalCase tokenizerName}}}PotentialToken[] {
    const potentialTokens: {{{pascalCase tokenizerName}}}PotentialToken[] = []

    let opener: {{{pascalCase tokenizerName}}}TokenDelimiter | null = null
    for (const delimiter of delimiters) {
      switch (delimiter.type) {
        case 'opener':
          opener = delimiter
          break
        case 'both':
          if (opener == null) {
            opener = delimiter
            break
          }
        case 'closer': {
          if (opener == null) break
          const closer = delimiter
          const potentialToken: {{{pascalCase tokenizerName}}}PotentialToken = {
            type: {{{pascalCase tokenizerName}}}Type,
            startIndex: opener.startIndex,
            endIndex: closer.endIndex,
            openerDelimiter: opener,
            closerDelimiter: closer,
            innerRawContents: [{
              startIndex: opener.endIndex,
              endIndex: closer.startIndex,
            }]
          }
          potentialTokens.push(potentialToken)
          opener = null
          break
        }
      }
    }
    return potentialTokens
  }

  /**
   * hook of @InlineTokenizerPreMatchPhaseHook
   */
  public assemblePreMatchState(
    rawContent: RawContent,
    potentialToken: {{{pascalCase tokenizerName}}}PotentialToken,
    innerState: InlineTokenizerPreMatchPhaseState[],
  ): {{{pascalCase tokenizerName}}}PreMatchPhaseState {
    const result: {{{pascalCase tokenizerName}}}PreMatchPhaseState = {
      type: {{{pascalCase tokenizerName}}}Type,
      startIndex: potentialToken.startIndex,
      endIndex: potentialToken.endIndex,
      openerDelimiter: potentialToken.openerDelimiter,
      closerDelimiter: potentialToken.closerDelimiter,
      children: innerState,
    }
    return result
  }

  /**
   * hook of @InlineTokenizerMatchPhaseHook
   */
  public match(
    rawContent: RawContent,
    preMatchPhaseState: {{{pascalCase tokenizerName}}}PreMatchPhaseState,
  ): {{{pascalCase tokenizerName}}}MatchPhaseState | false {
    const result: {{{pascalCase tokenizerName}}}MatchPhaseState = {
      type: {{{pascalCase tokenizerName}}}Type,
      startIndex: preMatchPhaseState.startIndex,
      endIndex: preMatchPhaseState.endIndex,
      openerDelimiter: preMatchPhaseState.openerDelimiter,
      closerDelimiter: preMatchPhaseState.closerDelimiter,
    }
    return result
  }

  /**
   * hook of @InlineTokenizerParsePhaseHook
   */
  public parse(
    rawContent: RawContent,
    matchPhaseState: {{{pascalCase tokenizerName}}}MatchPhaseState,
    parsedChildren?: InlineTokenizerParsePhaseState[],
  ): {{{pascalCase tokenizerName}}}DataNode {
    const result: {{{pascalCase tokenizerName}}}DataNode = {
      type: {{{pascalCase tokenizerName}}}Type,
      children: parsedChildren || [],
    }
    return result
  }
}
